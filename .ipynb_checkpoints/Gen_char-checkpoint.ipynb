{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba1a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6905d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "data_set=tf.keras.utils.get_file(\n",
    "    \"shakespeare.txt\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d9f634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of text is 1115394\n"
     ]
    }
   ],
   "source": [
    "text_data=open(data_set,\"rb\").read().decode(encoding=\"utf-8\")\n",
    "print(\"Lenght of text is\",len(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d264c77a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2696\\327022924.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dtype' is not defined"
     ]
    }
   ],
   "source": [
    "dtype(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad97d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text_data[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "694b41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab=set(text_data)\n",
    "vocab=sorted(vocab)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce06f42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b's', b'h', b'i', b'v', b'a', b'n'], [b's', b'i', b'n', b'g', b'h']]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts=[\"shivan\",\"singh\"]\n",
    "\n",
    "chars=tf.strings.unicode_split(example_texts, input_encoding=\"UTF-8\")\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "171b7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_char=tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "069b8808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[58, 47, 48, 61, 40, 53], [58, 48, 53, 46, 47]]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids=ids_from_char(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf66d42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b's', b'h', b'i', b'v', b'a', b'n'], [b's', b'i', b'n', b'g', b'h']]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_from_ids=tf.keras.layers.StringLookup(vocabulary=ids_from_char.get_vocabulary(), invert=True, mask_token=None)\n",
    "chars=char_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d5b00ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'shivan', b'singh'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d485f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(char_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6762fbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1], dtype=int64)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids=ids_from_char(tf.strings.unicode_split(text_data, \"UTF-8\"))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4eac5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset=tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9473d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(char_from_ids(ids).numpy().decode(\"UTF-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "580d9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=100\n",
    "ex_per_epoch=len(text_data) // (seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9533ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
      " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "seq=ids_dataset.batch(seq_len+1,drop_remainder=True)\n",
    "\n",
    "for seqs in seq.take(1):\n",
    "    print(char_from_ids(seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d15dec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "for seqs in seq.take(5):\n",
    "    print(text_from_ids(seqs).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3cb4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ip_target(seq):\n",
    "    ipt=seq[:-1]\n",
    "    tar=seq[1:]\n",
    "    return ipt,tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c46263d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['S', 'h', 'i', 'v', 'a'], ['h', 'i', 'v', 'a', 'n'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ip_target(list(\"Shivan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7b157883",
   "metadata": {},
   "outputs": [],
   "source": [
    " dataset=seq.map(split_ip_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8aa0c54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input - b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target - b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for ip, out in dataset.take(1):\n",
    "    print(\"Input -\", text_from_ids(ip).numpy())\n",
    "    print(\"Target -\", text_from_ids(out).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0f48f86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE=64\n",
    "BUFFER_SIZE=10000\n",
    "\n",
    "dataset=(\n",
    "     dataset.shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4bcb05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)\n",
    "em_dim=256\n",
    "rnn_units=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2047cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, em_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding=tf.keras.layers.Embedding(vocab_size,em_dim)\n",
    "        self.gru=tf.keras.layers.GRU(\n",
    "            rnn_units, return_sequences=True, return_state=True\n",
    "        )\n",
    "        self.dense=tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self,inputs,states=None,return_state=False,training=False):\n",
    "        x=self.embedding(inputs,training=training)\n",
    "        \n",
    "        if states is None:\n",
    "            states=self.gru.get_initial_state(x)\n",
    "        x, states=self.gru(x, initial_state=states, training=training)\n",
    "        x=self.dense(x, training=training)\n",
    "        \n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a7851877",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CharModel(\n",
    "    vocab_size=len(ids_from_char.get_vocabulary()),\n",
    "    em_dim=em_dim,\n",
    "    rnn_units=rnn_units,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1f2bd272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(\n",
    "        example_batch_predictions.shape,\n",
    "        \"# (batch_size, sequence_length, vocab_size)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c6ad0073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"char_model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     multiple                  16896     \n",
      "                                                                 \n",
      " gru_4 (GRU)                 multiple                  3938304   \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a8608652",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletf=tf.random.categorical(\n",
    "    example_batch_predictions[0], num_samples=1\n",
    ")\n",
    "sampletf=tf.squeeze(sampletf, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45fdb4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 40, 57, 61, 11, 65, 64, 35, 34, 34, 49,  3, 34,  9, 25, 17, 14,\n",
       "       42, 56, 31, 58, 61, 26, 13, 18, 30, 10, 59, 34,  8, 21, 44, 28, 27,\n",
       "       36, 58, 33, 19, 41, 27, 48, 22, 18,  2, 36, 30, 54, 44, 50, 18, 15,\n",
       "       29, 12, 11,  8, 35, 16, 62, 18, 65, 32, 50, 20, 49, 14, 24, 12, 59,\n",
       "        3, 40, 63, 44, 39, 12,  2, 56,  0, 29, 11, 52, 17, 39, 20, 32, 62,\n",
       "       49, 11, 12, 12, 47, 45, 34, 30, 64, 28, 42, 59, 33,  7, 46],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampletf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fd8ba1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      " b'nd blood, your flesh\\nand blood has not offended the king; and so your\\nflesh and blood is not to be p'\n",
      "\n",
      "Next Char Predict:\n",
      " b'iarv:zyVUUj!U.LDAcqRsvM?EQ3tU-HeONWsTFbNiIE WQoekEBP;:-VCwEzSkGjAK;t!axeZ; q[UNK]P:mDZGSwj:;;hfUQyOctT,g'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input\\n\",text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predict:\\n\",text_from_ids(sampletf).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b2556b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a9133ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66)\n",
      "Mean loss: tf.Tensor(4.1902914, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ex_batch_mean_loss=loss(target_example_batch,example_batch_predictions)\n",
    "print(example_batch_predictions.shape)\n",
    "\n",
    "print(\"Mean loss:\",ex_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4c85862c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.04203"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(ex_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2bf96353",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9895ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_pnt='./saves_char_gen'\n",
    "chkpnt_prefix=os.path.join(chk_pnt,\"cpkt_{epoch}\")\n",
    "chk_callback=tf.keras.callbacks.ModelCheckpoint(filepath=chkpnt_prefix,save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fab6665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "574e7cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "172/172 [==============================] - 495s 3s/step - loss: 2.7345\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 509s 3s/step - loss: 1.9975\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 511s 3s/step - loss: 1.7163\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 509s 3s/step - loss: 1.5536\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 474s 3s/step - loss: 1.4536\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 467s 3s/step - loss: 1.3847\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 471s 3s/step - loss: 1.3316\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 474s 3s/step - loss: 1.2859\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 503s 3s/step - loss: 1.2449\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 529s 3s/step - loss: 1.2039\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 555s 3s/step - loss: 1.1630\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 541s 3s/step - loss: 1.1218\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 488s 3s/step - loss: 1.0786\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 497s 3s/step - loss: 1.0321\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 509s 3s/step - loss: 0.9822\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 480s 3s/step - loss: 0.9311\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 477s 3s/step - loss: 0.8783\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 473s 3s/step - loss: 0.8247\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 466s 3s/step - loss: 0.7737\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 471s 3s/step - loss: 0.7248\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 469s 3s/step - loss: 0.6802\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 481s 3s/step - loss: 0.6382\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 491s 3s/step - loss: 0.6014\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 500s 3s/step - loss: 0.5721\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 499s 3s/step - loss: 0.5464\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 493s 3s/step - loss: 0.5246\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 509s 3s/step - loss: 0.5073\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 483s 3s/step - loss: 0.4927\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 487s 3s/step - loss: 0.4764\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 488s 3s/step - loss: 0.4661\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 482s 3s/step - loss: 0.4591\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 488s 3s/step - loss: 0.4515\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 488s 3s/step - loss: 0.4437\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 485s 3s/step - loss: 0.4400\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 504s 3s/step - loss: 0.4363\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 513s 3s/step - loss: 0.4321\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 494s 3s/step - loss: 0.4265\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 494s 3s/step - loss: 0.4215\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 493s 3s/step - loss: 0.4199\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 488s 3s/step - loss: 0.4192\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 492s 3s/step - loss: 0.4220\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 495s 3s/step - loss: 0.4209\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 494s 3s/step - loss: 0.4168\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 921s 5s/step - loss: 0.4171\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 491s 3s/step - loss: 0.4165\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 492s 3s/step - loss: 0.4176\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 485s 3s/step - loss: 0.4211\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 490s 3s/step - loss: 0.4195\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 484s 3s/step - loss: 0.4203\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 486s 3s/step - loss: 0.4230\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(dataset,epochs=EPOCHS, callbacks=[chk_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "79aabf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())],\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(\n",
    "            inputs=input_ids, states=states, return_state=True\n",
    "        )\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b56bac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, char_from_ids, ids_from_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8a064fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHIVAN:\n",
      "Sire--will be dann'd thou canst devise!\n",
      "\n",
      "ALONSO:\n",
      "Now, the Fortune lives, and this I'll knock\n",
      "A brace of justice,--I know'ty and knave all,\n",
      "The bloody favourites of the downfall of his life,\n",
      "As wealth, as quickly too much:\n",
      "I'll wait upon your good worshipful agone;\n",
      "And let his majesty I'll swing all that\n",
      "He use devotion's grow-consent.\n",
      "\n",
      "WARWICK:\n",
      "True, my good lord; I am not Licio,\n",
      "Nor a musician, as I see thee no\n",
      "children, and the duke that all\n",
      "From forth traitor's and--maderby, methinks, I\n",
      "extered themselves to quarrel with the deep tread, he\n",
      "is an ash again two swords.\n",
      "\n",
      "AUFIDIUS:\n",
      "My lord,\n",
      "Is there an ensibe, I'll break our sea-curning\n",
      "Whiles one word more. They are not in't, nor wrong'd\n",
      "Upon the lark and leaves unto his ears?\n",
      "And any think it was the nobler keeper's well,\n",
      "Were ship, to expol him that title, that enseas\n",
      "For to Capuletable ask.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "Where I have leave to lay meditation.\n",
      "\n",
      "CORIOLANUS:\n",
      "Why force you now?\n",
      "\n",
      "First Senator:\n",
      "Speak all. RAMeRIO:\n",
      "How far he is already had \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 2.802264928817749\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant([\"SHIVAN:\\nSire\"])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(\n",
    "        next_char, states=states\n",
    "    )\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode(\"utf-8\"), \"\\n\\n\" + \"_\" * 80)\n",
    "print(\"\\nRun time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bcc969b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x000001DE98CFACA0>, because it is not built.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, \"one_step\")\n",
    "one_step_reloaded = tf.saved_model.load(\"one_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be339626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
